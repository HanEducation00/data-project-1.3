#!/usr/bin/env python3
"""
KAFKA CONSUMER - DOCKER NETWORK Ä°Ã‡Ä°N FÄ°X
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *

def create_spark_session():
    """Docker network iÃ§in Spark session"""
    return SparkSession.builder \
        .appName("Seasonal_Energy_Kafka_Consumer") \
        .config("spark.jars.packages", 
                "org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0") \
        .config("spark.sql.adaptive.enabled", "true") \
        .master("local[2]") \
        .getOrCreate()

def setup_kafka_consumer(spark, topic_name="sensor-data"):
    """Docker network iÃ§inde Kafka consumer"""
    
    kafka_config = {
        # âœ… FIX: Docker network isimleri
        "kafka.bootstrap.servers": "development-kafka1:19092,development-kafka2:29092,development-kafka3:39092",
        "subscribe": topic_name,
        "startingOffsets": "earliest",
        "endingOffsets": "latest",
        "failOnDataLoss": "false"
    }
    
    print(f"ğŸ“¨ Kafka'ya baÄŸlanÄ±yor: {topic_name}")
    print(f"ğŸ”— Brokers: {kafka_config['kafka.bootstrap.servers']}")
    
    try:
        kafka_df = spark.read \
            .format("kafka") \
            .options(**kafka_config) \
            .load()
        
        print(f"âœ… Kafka consumer hazÄ±r!")
        return kafka_df
        
    except Exception as e:
        print(f"âŒ Kafka baÄŸlantÄ± hatasÄ±: {e}")
        raise

def simple_kafka_test():
    """Basit Kafka baÄŸlantÄ± testi"""
    
    print("ğŸ§ª KAFKA BAÄLANTI TESTÄ°")
    print("="*40)
    
    spark = None
    try:
        spark = create_spark_session()
        print("âœ… Spark session oluÅŸturuldu")
        
        kafka_df = setup_kafka_consumer(spark, "sensor-data")
        
        # Sadece schema kontrolÃ¼ (count yapmadan)
        print("ğŸ“‹ Kafka DataFrame schema:")
        kafka_df.printSchema()
        
        print("âœ… Kafka baÄŸlantÄ± testi baÅŸarÄ±lÄ±!")
        return True
        
    except Exception as e:
        print(f"âŒ Test baÅŸarÄ±sÄ±z: {e}")
        return False
        
    finally:
        if spark:
            spark.stop()

if __name__ == "__main__":
    simple_kafka_test()
